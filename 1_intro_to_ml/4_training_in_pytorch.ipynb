{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "677500e2-d1b2-44bb-b588-fa978d646914",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "In the previous modules, we created a simple neural network from scratch. This is great for learning and perhaps not as useful when it comes to real world ML and efficiency! Now we will learn just enough PyTorch to get off the ground making ML models using the power of the framework.\n",
    "\n",
    "\n",
    "### Why PyTorch?\n",
    "\n",
    "Other frameworks such as JAX and MXNET have their pros and cons, PyTorch is most suitable for this course since its learning curve is fairly short, its efficiencies are more than enough for our practical implementations, and, as you start to read research papers and explore models out there, PyTorch tends to be the more ubiquitous. \n",
    "\n",
    "### Synopsis\n",
    "\n",
    "In this notebook, we will cover:\n",
    "* Tensors - the core data structure of ML\n",
    "* Autograd - automatic differentiation\n",
    "* torch.nn - the neural network module\n",
    "* Optimizers - for model training\n",
    "* Loss functions - for calculating the error\n",
    "* Data loading - for loading datasets and batching\n",
    "* GPU support - makes use of CUDA if available\n",
    "* Model saving and loading - for doing things with our models!\n",
    "* Some useful utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838e787-9c28-4b93-b2b3-16261910a614",
   "metadata": {},
   "source": [
    "### Installing PyTorch\n",
    "\n",
    "Choose the relevant option at [pytorch.org](https://pytorch.org/get-started/locally/#linux-pip) for your system. If you're on Colab, you can switch to the free GPU (T4) to try the CUDA version. Here, we install the CPU-only package, which should be fine for this notebook.\n",
    "\n",
    "If you need to check your CUDA version, try\n",
    "``` \n",
    "nvcc --version\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a26aa-f182-4816-a490-d113f423e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio torchviz --index-url https://download.pytorch.org/whl/cpu --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb59329-cf48-4bf8-8ffc-ff22a7b113f7",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Until now, we have worked with Numpy arrays. Tensors are similar however have many added abilities, including:\n",
    "\n",
    "* GPU support\n",
    "* Automatic differentiation - compute gradients through autograd (more on this soon).\n",
    "* Supported data types, including a broad range of complex numbers and precision types.\n",
    "\n",
    "If you're already familiar with Numpy and numpy.array, PyTorch operations will feel very similar. \n",
    "\n",
    "Tensors are arrays of numerical values such as scalars, vectors and matricies. They can be of any dimension. Dimensions of tensors are commonly called \"rank\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91139664-e24a-4930-bc03-aa3076921238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "tensor = torch.rand(3,4)\n",
    "print(f\"Tensor = {tensor}\")\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6e6580-7270-49e0-8d6e-74644f35ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar\n",
    "scalar = torch.tensor(5)\n",
    "print(f\"Scalar rank: {scalar.dim()}\")\n",
    "\n",
    "# Vector\n",
    "vec = torch.tensor([1, 2, 3])\n",
    "print(f\"Vector rank: {vec.dim()}\")\n",
    "\n",
    "# Matrix\n",
    "mat = torch.tensor([[1, 2], [3, 4]])\n",
    "print(f\"Matrix rank: {mat.dim()}\")\n",
    "\n",
    "# 3D Tensor\n",
    "tensor3d = torch.tensor([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(f\"3D tensor rank: {tensor3d.dim()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81d8dd5-12ba-4304-ad35-5f50d132e61d",
   "metadata": {},
   "source": [
    "#### Shape and Reshaping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d04d06-2be4-4f94-bbe8-a2a33d820cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(2, 3)\n",
    "print(f\"x = {x}\")\n",
    "print(f\"size = {x.shape}\")\n",
    "\n",
    "reshaped = x.view(3,2)\n",
    "print(f\"\\nreshaped = {reshaped}\")\n",
    "print(f\"size = {reshaped.shape}\")\n",
    "\n",
    "y = torch.rand(2, 3, 4)\n",
    "y_permuted = y.permute(2,0,1)\n",
    "print(f\"\\ny = {y}\")\n",
    "print(f\"\\npermuted = {y_permuted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379ca09d-50ec-415e-8986-ef35546eda77",
   "metadata": {},
   "source": [
    "#### Tensor Mathematics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef3869-42d2-4677-a5f7-cf82c12b00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1.0, 2.0])\n",
    "print(f\"a: {a}\")\n",
    "\n",
    "b = torch.tensor([3.0, 4.0])\n",
    "print(f\"b: {b}\")\n",
    "\n",
    "add = a + b                     # elementwise addition\n",
    "print(f\"add: {add}\")\n",
    "\n",
    "mul = a * b                     # elementwise multiplication\n",
    "print(f\"multiply: {mul}\")\n",
    "\n",
    "dot = torch.dot(a, b)           # dot product\n",
    "print(f\"dot product: {dot}\")\n",
    "\n",
    "matmul = torch.matmul(a.view(1, 2), b.view(2, 1))  # matrix multiplication\n",
    "print(f\"matrix multiplication: {matmul}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b643e3a-215b-4e7f-be3a-4b0fe247c464",
   "metadata": {},
   "source": [
    "#### Indexing and Slicing\n",
    "\n",
    "It be useful to to return an index or part of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e5a21-7e63-41ee-a6ec-572d57bf1c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(x[0, 1])      # 2 (row 0, col 1)\n",
    "print(x[:, 1])      # tensor([2, 5]) — all rows, col 1\n",
    "print(x[1])         # tensor([4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a0475-4eb0-4620-91e5-b040327d996e",
   "metadata": {},
   "source": [
    "#### Device and Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d319c-988b-486a-a8b4-44cb356afcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "x = torch.tensor([1.0, 2.0], device=device)\n",
    "\n",
    "\n",
    "\n",
    "# Change data type\n",
    "y = torch.tensor([1, 2, 3], dtype=torch.float32)\n",
    "print(f\"y: {y}\")\n",
    "print(f\"y type: {y.type()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e48b91c-af22-4334-a601-9098bbf473cf",
   "metadata": {},
   "source": [
    "#### Gradients and Autograd\n",
    "\n",
    "Remember our long-winded backpropagation calculations from the previous notebooks? PyTorch uses a system called autograd to compute gradients of tensors automatically during backpropagation. By using `requires_grad=True`, PyTorch builds a computational graph, then calling `.backward()` computes gradients with respect to the inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4428b42-99f8-4f44-97ac-351a31ed1ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
    "y = x**2 + 3*x\n",
    "y.sum().backward()\n",
    "\n",
    "print(x.grad)  # dy/dx for each element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919a00f1-5004-4a01-844a-f91aab6373d2",
   "metadata": {},
   "source": [
    "### The Neural Network Module\n",
    "\n",
    "PyTorch makes it easy to slot together various components to build a neural network. \n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Have a read of the [torch.nn](https://docs.pytorch.org/docs/stable/nn.html) module, in particular the following methods:\n",
    "```\n",
    "nn.Flatten\n",
    "nn.Linear\n",
    "nn.ReLU\n",
    "```\n",
    "\n",
    "What would this network look like, using the above methods?\n",
    "\n",
    "```\n",
    "class SimpleNN(nn.Module):\n",
    "    def__init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Flatten 28 x 28 images to 784 tensor\n",
    "        # Fully connected layer 1, with 784 in_features and 128 out_features\n",
    "        # ReLU activation \n",
    "        # Fully connected layer 2, with 128 in_features and 10 classes as out_features\n",
    "```\n",
    "\n",
    "Read the documentation and try to fill in the four lines below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a534f05-b931-4a94-970c-5eb127dceb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        # Flatten 28 x 28 images to 784 tensor\n",
    "        # Fully connected layer 1, with 784 in_features and 128 out_features\n",
    "        # ReLU activation \n",
    "        # Fully connected layer 2, with 128 in_features and 10 classes as out_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81345c1b-fb60-48fa-8451-97aa1be6404a",
   "metadata": {},
   "source": [
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e94501-2e20-4805-ba1d-5ccf905cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flattens 28x28 to 784\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for digits 0–9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0575c5-0a21-42fd-af6c-2086e72eee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_simplenn_layers():\n",
    "    model = SimpleNN()\n",
    "\n",
    "    # Test fc1 input/output dimensions\n",
    "    assert model.fc1.in_features == 784, \"fc1 input should be 784\"\n",
    "    assert model.fc1.out_features == 128, \"fc1 output should be 128\"\n",
    "\n",
    "    # Test fc2 input/output dimensions\n",
    "    assert model.fc2.in_features == 128, \"fc2 input should be 128\"\n",
    "    assert model.fc2.out_features == 10, \"fc2 output should be 10\"\n",
    "\n",
    "    # Test layer types\n",
    "    assert isinstance(model.flatten, nn.Flatten), \"Missing or incorrect flatten layer\"\n",
    "    assert isinstance(model.relu, nn.ReLU), \"Missing or incorrect ReLU layer\"\n",
    "\n",
    "    \n",
    "try:\n",
    "    test_simplenn_layers()\n",
    "    print(\"✅ All tests passed.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"❌ Test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e2f2c-4838-41b0-bd4e-182485668048",
   "metadata": {},
   "source": [
    "### Building out the network\n",
    "\n",
    "Since we now have a model, let's continue to build a working example for MNIST. \n",
    "\n",
    "#### Feed Forward Step\n",
    "\n",
    "Our feed forward step is straightforward, since we simply move our calculations through the network. We will add it to our SimpleNN class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72bf1ea-05ed-471b-a4e2-cea375bcb193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flattens 28x28 to 784\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for digits 0–9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)  # No softmax here (handled by loss function)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bff253-d239-4fef-b89b-edb89e54c0bf",
   "metadata": {},
   "source": [
    "#### Set the Device\n",
    "\n",
    "Just as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc4b8b-afb6-4d37-a9f5-8d80e105aace",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f41cf1-d372-4d32-a949-9910e79fe19a",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "Working with datasets is generally straightforward in PyTorch since we can import many of the better-known ones. [Datasets](https://docs.pytorch.org/vision/main/datasets.html) comes as part of the 'Torchvision' library, part of the same project as PyTorch. \n",
    "\n",
    "Have a look at the list of datasets, they are great for quick exploration and code samples abound! \n",
    "\n",
    "[This tutorial](https://docs.pytorch.org/tutorials/beginner/basics/data_tutorial.html) on Datasets & DataLoaders is worth reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223f0d8-11ca-4d1d-a838-8842edad53f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.ToTensor() # converts images to tensors\n",
    "train_data = datasets.MNIST(root='.', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb13f8-2f80-4deb-bb0f-e4104c04a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4648859-4508-4227-9e84-da60120379d4",
   "metadata": {},
   "source": [
    "### Initialize Model, Loss, Optimizer\n",
    "\n",
    "Here we instantiate our model class and set up the loss and optimizer.\n",
    "\n",
    "#### A Word on Optimizers\n",
    "We have covered activations, however didn't have an optimizer in the toy neural network which we built in Python in the third module. \n",
    "\n",
    "An *optimizer* is simply a function that governs updating the neural network's parameters (the weights and biases) based on the gradients during backpropagation. In our toy example, we simply used gradient descent. Similarly, we could just have used the PyTorch equivalent, `optim.SGD`, however there are also more sophisticated options. Have a look at the documentation [here](https://docs.pytorch.org/docs/stable/optim.html).\n",
    "\n",
    "In this example, we will use Adam, which maintains a moving average of the gradients and their squared values, providing adaptive learning rates for each parameter. This can lead to faster convergence, learning rate adaption for each parameter, and better handling of sparse gradients.\n",
    "\n",
    "### Initialize the model, loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de403d1-8048-4f3e-aedd-ee3c42a654bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss, optimizer\n",
    "model = SimpleNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8260cf53-1763-412a-bc67-c84b5f3c414b",
   "metadata": {},
   "source": [
    "### Visualizing the Model\n",
    "\n",
    "It can be helpful to visualize the layers and shapes of tensors at each layer. We will use `torchviz` to create a visual graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3152e2bd-8157-4ec7-9b51-8c6524295bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8776df32-e638-498a-aeb5-d11beac15125",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U git+https://github.com/szagoruyko/pytorchviz.git@master --quiet\n",
    "from torchviz import make_dot, make_dot_from_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f020bbbc-0341-4319-aa69-92112e38d779",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "# Dummy input to trace the computation graph\n",
    "x = torch.randn(1, 1, 28, 28).to(device)\n",
    "y = model(x)\n",
    "\n",
    "# Draw graph\n",
    "make_dot(y, params=dict(model.named_parameters())).render(\"model_architecture\", format=\"png\")\n",
    "\n",
    "# Display the saved image\n",
    "Image(filename=\"model_architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a725df9-720c-4a80-a061-7fcb231d2f03",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "Let's put it all together. We just need to call our images from the DataLoader, run them through the model and perform the updates to model weights as the model checks how wrong it is.\n",
    "\n",
    "Here we see `num_epochs`, which sets the number of times we compute a full pass of the dataset through the model (hopefully improving its predictions every time). \n",
    "\n",
    "We also set up some variables to hold how well the model is learning, which make printing progress easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c63e9-8388-454f-af02-d54303bba901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Assuming model, optimizer, criterion, train_loader already defined\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        # Print progress every N batches\n",
    "        if (batch_idx + 1) % 250 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], \"\n",
    "                  f\"Loss: {loss.item():.4f}, Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "    # Print end-of-epoch summary\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    print(f\"Epoch {epoch+1} finished - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59db2ccd-9edc-42b4-b915-9c22d2843802",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can then evaluate the model on a sample group of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368f5f22-93c0-4cb9-805c-d7ed0d392aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Get a batch of images and labels\n",
    "    sample_img, sample_label = next(iter(train_loader))\n",
    "    sample_img, sample_label = sample_img.to(device), sample_label.to(device)\n",
    "\n",
    "    # Get predictions\n",
    "    pred = model(sample_img)\n",
    "    predicted_class = torch.argmax(pred, dim=1)\n",
    "\n",
    "    # Move everything to CPU for plotting\n",
    "    images = sample_img.cpu()\n",
    "    labels = sample_label.cpu()\n",
    "    predictions = predicted_class.cpu()\n",
    "\n",
    "    # Create a grid of images (make_grid normalizes automatically)\n",
    "    grid = torchvision.utils.make_grid(images[:10], nrow=5, padding=2, normalize=True)\n",
    "\n",
    "    # Plot the grid\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(grid.permute(1, 2, 0))  # CxHxW to HxWxC\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Predictions vs. Ground Truth\", fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # Print predictions and labels for first 16\n",
    "    print(\"Predicted:\", predictions[:10].tolist())\n",
    "    print(\"Actual:   \", labels[:10].tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0993fa40-e3fc-471f-a150-65bfc89852f6",
   "metadata": {},
   "source": [
    "### Saving and Loading Models\n",
    "\n",
    "There are three options for model saving:\n",
    "* `torch.save` saves a serialized object to disk, using Python's pickle utility.\n",
    "* `torch.load` uses pickle to deserialize pickled object files to memory.\n",
    "* `torch.nn.Module.load_state_dict` loads a model's parameter dictionary. A 'state_dict' is a Python dictionary object that maps each layer to its parameter tensor.\n",
    "* A common PyTorch convention is to save models using either a .pt or .pth file extension.\n",
    "* For more information on saving and loading, please see the [documentation](https://docs.pytorch.org/tutorials/beginner/saving_loading_models.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbafa3b-3c0c-43ce-a1fc-cac3c0d24c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model, \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37a57a-a00c-4259-a10a-265d59fe4b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model = torch.load(\"model.pth\", weights_only=False)\n",
    "# Check the model architecture\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ae2ae-ff7e-4e28-aaf4-145a3b466b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddfaa8-3755-4e81-8783-1087a9ff7f1e",
   "metadata": {},
   "source": [
    "### Utilities\n",
    "\n",
    "Finally, we will briefly cover some utility functions.\n",
    "\n",
    "#### torch.argmax\n",
    "\n",
    "Returns the index of the maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6e779f-a7c9-495c-a08c-638ad55f9148",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 3.0, 2.0])\n",
    "idx = torch.argmax(x)\n",
    "print(idx)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9017121-c8b7-4d73-bbdc-326cb577f2e5",
   "metadata": {},
   "source": [
    "#### torch.max()\n",
    "\n",
    "Returns maximum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6cad8-1ef6-451f-8e12-f1997073b974",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 3.0, 2.0])\n",
    "max_val = torch.max(x)\n",
    "print(max_val)  # Output: 3.0\n",
    "\n",
    "# Along a dimension\n",
    "x2 = torch.tensor([[1, 5], [4, 2]])\n",
    "max_vals, indices = torch.max(x2, dim=1)\n",
    "print(max_vals)   \n",
    "print(indices)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f625c9ad-8665-468a-8cf9-6c46dc54d557",
   "metadata": {},
   "source": [
    "#### torch.sum()\n",
    "\n",
    "Sums all elements along a dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06267446-e0e2-41ff-848b-b4d134fd356d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[1, 2], [3, 4]])\n",
    "total = torch.sum(x)\n",
    "print(total) \n",
    "\n",
    "sum_dim0 = torch.sum(x, dim=0)\n",
    "print(sum_dim0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0d5ed-b7a7-43db-9a33-aba9689d5f33",
   "metadata": {},
   "source": [
    "#### torch.no_grad()\n",
    "\n",
    "Disables gradient tracking, useful during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4488b-1853-4486-8949-63c3103c3a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(2, 1)\n",
    "input = torch.tensor([[1.0, 2.0]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "    print(output)  # No gradients are tracked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca2ce5-4958-415d-abb3-6aa51060ca55",
   "metadata": {},
   "source": [
    "#### torch.manual_seed()\n",
    "\n",
    "Sets a seed so we can reproduce experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e7f3f-c57e-4902-9171-6d75917f8075",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "x = torch.randn(2)\n",
    "print(x)  # Same output each run with the same seed\n",
    "print(x)\n",
    "print(\"\\n\")\n",
    "\n",
    "torch.manual_seed(22)\n",
    "y = torch.randn(2)\n",
    "print(y)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74db7e44-78e7-4dc8-9d22-9ca534fa5c09",
   "metadata": {},
   "source": [
    "### Wrap up\n",
    "\n",
    "In this notebook, we covered the principle features of PyTorch including tensor manipulation and mathematical operations, model creation, training, evaluation, saving and loading, as well as some useful utilities.\n",
    "\n",
    "This concludes our first module. Now that we have some familiarity with how neural networks learn, have a play around! Try tweaking the model arhitecture to use more layers, or try a different optimizer and compare the training and evaluation runs. Experiment with some of the TorchVision datasets to go beyond MNIST."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
