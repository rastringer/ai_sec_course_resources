{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16d04798-ff82-4ec7-961e-97187d42f3b4",
   "metadata": {},
   "source": [
    "### Differential Privacy\n",
    "\n",
    "Differential privacy is a mathematical approach to preserving statistical and useful information in datasets without comprising the privacy of the individuals whose data is included. DP means datasets can reveal patterns which limiting any disclosure of individual information.\n",
    "\n",
    "This is commonly achieved by adding noise to analytic outputs to mask indivudial input that influenced the calculation. DP should guarantee that a dataset will produce almost identical analytical results (such as average age) if a single entry is removed.\n",
    "\n",
    "More formally, DP uses a randomized algorithm M which satisfies Œµ-differential privacy if for all datasets D‚ÇÅ, D‚ÇÇ differing by one record, and all outputs S:   \n",
    "\n",
    "$$Pr[M(D‚ÇÅ) ‚àà S] ‚â§ e^Œµ √ó Pr[M(D‚ÇÇ) ‚àà S]$$\n",
    "\n",
    "This basically means that changing one of the data samples barely affects the output.\n",
    "\n",
    "### Application to Machine Learning\n",
    "\n",
    "DP is essential in data-hungry machine learning to preserve privacy in training data. Noise is often added either to training data (so the model doesn't learn sensitive information), or to gradients of the loss function during training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f271aa6-0439-44df-8c82-33dc7301fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import laplace, norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eb94bf-91dc-44f5-bed8-bbd0e314a37a",
   "metadata": {},
   "source": [
    "# Anonymized datasets\n",
    "\n",
    "Let's make a synthetic medical dataset. We will test its basic anonymization, which in this case is the lack of names, addresses and other potentially identifiable information (PII). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92530a78-f9b4-47ba-b047-39fa2706bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_medical_dataset(n=1000):\n",
    "    \"\"\"Create synthetic medical data that looks anonymized but isn't\"\"\"\n",
    "    ages = np.random.normal(45, 15, n).astype(int)\n",
    "    ages = np.clip(ages, 18, 90)\n",
    "    \n",
    "    # Zip codes (let's say we're in a specific region)\n",
    "    zip_codes = np.random.choice([10001, 10002, 10003, 10004, 10005], n, \n",
    "                                p=[0.3, 0.25, 0.2, 0.15, 0.1])\n",
    "    \n",
    "    # Medical condition (higher probability for older people)\n",
    "    condition_prob = (ages - 18) / 72 * 0.6 + 0.1\n",
    "    has_condition = np.random.binomial(1, condition_prob, n)\n",
    "    \n",
    "    # Salary (correlated with zip code and age)\n",
    "    base_salary = np.random.choice([40000, 50000, 60000, 70000, 80000], n,\n",
    "                                  p=[0.2, 0.3, 0.25, 0.15, 0.1])\n",
    "    salary_noise = np.random.normal(0, 5000, n)\n",
    "    salaries = base_salary + (ages - 30) * 500 + salary_noise\n",
    "    salaries = np.clip(salaries, 25000, 120000)\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'age': ages,\n",
    "        'zip_code': zip_codes,\n",
    "        'salary': salaries.astype(int),\n",
    "        'has_rare_disease': has_condition\n",
    "    })\n",
    "\n",
    "# Generate our dataset\n",
    "df_medical = create_medical_dataset(1000)\n",
    "\n",
    "# Show basic statistics\n",
    "print(f\"   - {len(df_medical)} patients\")\n",
    "print()\n",
    "print(df_medical.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee1a9c3-733f-4a29-a525-eae26eeaf777",
   "metadata": {},
   "source": [
    "Let's think for a minute, what issues are inherent in such a dataset?\n",
    "\n",
    "### Privacy attack\n",
    "\n",
    "Imagine an attacker knows some basic information about a target, or even their neighbour, such as:\n",
    "* 34 years old\n",
    "* Lives in zip code 10001\n",
    "* Makes around $55,000\n",
    "\n",
    "and they want to find out if their target or neighbour has a rare disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54917390-a2df-454b-a76c-574f7d0efcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_age = 34\n",
    "target_zip = 10001\n",
    "target_salary_range = (50000, 60000)\n",
    "\n",
    "print(f\"\\nSearching for matches in our 'anonymous' database...\")\n",
    "\n",
    "matches = df_medical[\n",
    "    (df_medical['age'] == target_age) & \n",
    "    (df_medical['zip_code'] == target_zip) &\n",
    "    (df_medical['salary'].between(target_salary_range[0], target_salary_range[1]))\n",
    "]\n",
    "\n",
    "print(f\"Found {len(matches)} potential matches:\")\n",
    "print(matches[['age', 'zip_code', 'salary', 'has_rare_disease']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ce01bf-c522-48dd-97f2-1293b2cce94e",
   "metadata": {},
   "source": [
    "We can see two close matches to the target, one of whom has the rare disease. The attacker could look for further information to confirm whether the affected individual is the original target, or try to find out who the positive case is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb2424-20cf-4a9e-9a2e-44fbc3fa899e",
   "metadata": {},
   "source": [
    "### Laplace mechanism\n",
    "\n",
    "Let's experiment with differential privacy by adding Laplace noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd8ca69-b0cc-4773-88f0-378f54b7aa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The count of people with the rare disease\n",
    "# This number of course shouldn't be disclosed since\n",
    "# it may leak info\n",
    "true_count = df_medical['has_rare_disease'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eaf4f0-eecb-41fa-b872-10b0ad47bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_mechanism(true_value, epsilon, sensitivity=1):\n",
    "    \"\"\"\n",
    "    The Laplace Mechanism for differential privacy\n",
    "    \n",
    "    Args:\n",
    "        true_value: The actual value to protect\n",
    "        epsilon: Privacy parameter (smaller = more private)\n",
    "        sensitivity: Maximum change in output from changing one record\n",
    "    \"\"\"\n",
    "    scale = sensitivity / epsilon  # More privacy (smaller Œµ) = more noise\n",
    "    noise = np.random.laplace(0, scale)\n",
    "    return true_value + noise\n",
    "\n",
    "print(f\"\\nüé≤ Adding Laplace noise to protect the count...\")\n",
    "print(\"Let's try different privacy levels (epsilon values):\")\n",
    "print()\n",
    "\n",
    "# Show effect of different epsilons\n",
    "epsilons = [0.1, 1.0, 10.0]\n",
    "print(f\"{'Epsilon':<8} {'Noisy Count':<12} {'Error':<10} {'Privacy Level'}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for eps in epsilons:\n",
    "    noisy_count = laplace_mechanism(true_count, eps)\n",
    "    error = abs(noisy_count - true_count)\n",
    "    \n",
    "    privacy_level = \"High\" if eps < 1 else \"Medium\" if eps < 5 else \"Low\"\n",
    "    print(f\"{eps:<8} {noisy_count:<12.1f} {error:<10.1f} {privacy_level}\")\n",
    "\n",
    "print(f\"\\nKey insight: Lower epsilon = more privacy = more noise = less accuracy!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3379399-b821-423a-84f3-39d7fdf132a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_with_epsilon():\n",
    "    \"\"\"Experiment with different epsilon values\"\"\"\n",
    "    \n",
    "    # Change this value and re-run!\n",
    "    EPSILON = 1.0  # Try 0.01, 0.1, 1.0, 10.0\n",
    "    \n",
    "    print(f\"Experiment: Œµ = {EPSILON}\")\n",
    "    \n",
    "    # Run multiple trials\n",
    "    results = []\n",
    "    for i in range(5):\n",
    "        noisy_count = laplace_mechanism(true_count, EPSILON)\n",
    "        error = abs(noisy_count - true_count)\n",
    "        results.append((noisy_count, error))\n",
    "        print(f\"   Trial {i+1}: {noisy_count:.1f} (error: {error:.1f})\")\n",
    "    \n",
    "    avg_error = np.mean([r[1] for r in results])\n",
    "    print(f\"   Average error: {avg_error:.1f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run the experiment\n",
    "experiment_results = experiment_with_epsilon()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292fdfad-824b-4fd1-84b2-6b35ab2c12fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate tradeoff data\n",
    "def generate_tradeoff_data():\n",
    "    epsilon_values = np.logspace(-1, 1.5, 15)  # From 0.1 to ~30\n",
    "    n_trials = 20\n",
    "    \n",
    "    avg_errors = []\n",
    "    \n",
    "    for epsilon in epsilon_values:\n",
    "        errors = []\n",
    "        for _ in range(n_trials):\n",
    "            noisy_count = laplace_mechanism(true_count, epsilon)\n",
    "            error = abs(noisy_count - true_count)\n",
    "            errors.append(error)\n",
    "        avg_errors.append(np.mean(errors))\n",
    "    \n",
    "    return epsilon_values, avg_errors\n",
    "\n",
    "print(\"Running experiments across different privacy levels...\")\n",
    "epsilons, errors = generate_tradeoff_data()\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.semilogx(epsilons, errors, 'b-o', linewidth=2, markersize=6)\n",
    "plt.xlabel('Epsilon (Privacy Parameter)', fontsize=12)\n",
    "plt.ylabel('Average Absolute Error', fontsize=12)\n",
    "plt.title('Privacy-Utility Tradeoff: More Privacy = More Error', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add annotations\n",
    "plt.axvline(x=1.0, color='red', linestyle='--', alpha=0.7)\n",
    "plt.annotate('Œµ=1.0\\n(Common threshold)', xy=(1.0, max(errors)*0.8), \n",
    "             xytext=(3, max(errors)*0.8), fontsize=10,\n",
    "             arrowprops=dict(arrowstyle='->', color='red', alpha=0.7))\n",
    "\n",
    "# Add privacy level regions\n",
    "plt.axvspan(0.1, 0.5, alpha=0.2, color='green', label='High Privacy')\n",
    "plt.axvspan(0.5, 5.0, alpha=0.2, color='yellow', label='Medium Privacy')  \n",
    "plt.axvspan(5.0, 30, alpha=0.2, color='red', label='Low Privacy')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b175e48-ab32-41c6-8218-c6a9cde6357e",
   "metadata": {},
   "source": [
    "Obviously, a high degree of privacy seems to come at the cost of accuracy. \n",
    "How might this tradeoff affect real-world deployments or analytics?\n",
    "\n",
    "### Privacy budget\n",
    "\n",
    "Each time we ask a question of a database, we use up part of our privacy budget. The amount we use depends on how much privacy we want to 'spend' on a question. This is the epsilon value we pass into the query.\n",
    "\n",
    "`epsilon_budget` is the total privacy budget the database starts with.\n",
    "`epsilon_spent` tracks how much has already been used.\n",
    "Each query consumes some portion (epsilon) of that budget.\n",
    "\n",
    "\n",
    "Since DP works by adding carefully calibrated noise (here we use Laplace) to hide individual contributions to the overall data. However, if we ask too many questions, even noisy answers can be combined to reconstruct private information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ca7a28-95e3-4bf8-b9cb-6f782bb261ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DifferentiallyPrivateDatabase:\n",
    "    def __init__(self, data, epsilon_budget=1.0):\n",
    "        self.data = data\n",
    "        self.epsilon_budget = epsilon_budget\n",
    "        self.epsilon_spent = 0.0\n",
    "        print(f\"DP Database created with privacy budget Œµ = {epsilon_budget}\")\n",
    "        \n",
    "    def check_privacy_budget(self, epsilon_needed):\n",
    "        if self.epsilon_spent + epsilon_needed > self.epsilon_budget:\n",
    "            raise ValueError(f\"Privacy budget exceeded! \"\n",
    "                           f\"Spent: {self.epsilon_spent:.2f}, \"\n",
    "                           f\"Need: {epsilon_needed}, \"\n",
    "                           f\"Budget: {self.epsilon_budget}\")\n",
    "    \n",
    "    def count_query(self, condition_column, condition_value, epsilon):\n",
    "        \"\"\"Count records satisfying a condition\"\"\"\n",
    "        print(f\"Running count query with Œµ = {epsilon}\")\n",
    "        self.check_privacy_budget(epsilon)\n",
    "        \n",
    "        # True count\n",
    "        true_count = (self.data[condition_column] == condition_value).sum()\n",
    "        \n",
    "        # Add Laplace noise (sensitivity = 1 for counting)\n",
    "        noisy_count = laplace_mechanism(true_count, epsilon, sensitivity=1)\n",
    "        noisy_count = max(0, int(round(noisy_count)))  # Counts can't be negative\n",
    "        \n",
    "        self.epsilon_spent += epsilon\n",
    "        print(f\"   True count: {true_count}\")\n",
    "        print(f\"   DP count: {noisy_count}\")\n",
    "        print(f\"   Remaining budget: Œµ = {self.remaining_budget():.2f}\")\n",
    "        \n",
    "        return noisy_count\n",
    "    \n",
    "    def remaining_budget(self):\n",
    "        return self.epsilon_budget - self.epsilon_spent\n",
    "\n",
    "# Create our DP database\n",
    "dp_db = DifferentiallyPrivateDatabase(df_medical, epsilon_budget=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2043c4f8-b65c-4a14-a4c5-280871f8ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nQuery 1: How many people have the rare disease?\")\n",
    "try:\n",
    "    disease_count = dp_db.count_query('has_rare_disease', 1, epsilon=0.3)\n",
    "    print(f\"Query successful!\")\n",
    "except ValueError as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "print(f\"\\nQuery 2: How many people live in zip code 10001?\")\n",
    "try:\n",
    "    zip_count = dp_db.count_query('zip_code', 10001, epsilon=0.3)\n",
    "    print(f\"Query successful!\")\n",
    "except ValueError as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "print(f\"\\nQuery 3: How many people are exactly 34 years old?\")\n",
    "try:\n",
    "    age_count = dp_db.count_query('age', 34, epsilon=0.5)\n",
    "    print(f\"Query successful!\")\n",
    "except ValueError as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "print(f\"\\nQuery 4: One more query...\")\n",
    "print(\"What happens if we try another query?\")\n",
    "try:\n",
    "    another_count = dp_db.count_query('zip_code', 10002, epsilon=0.3)\n",
    "    print(f\"Query successful!\")\n",
    "except ValueError as e:\n",
    "    print(f\"{e}\")\n",
    "    print(\"This is privacy budget depletion in action!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62e9627-aaf2-4899-b12e-720ac21fda7b",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Experiment with parameters\n",
    "    * Modify the EPSILON, try 0.01, 0.1, 10.0, 100.0\n",
    "    * At what point does the noise become excessive?\n",
    "2. Create your own attack\n",
    "    * Add more quasi-indentifiers to the medical dataset\n",
    "    * Try to identify individuals with 2-3 attributes\n",
    "    * How unique are people in high-dimensional data?\n",
    "3. Think like an attacker\n",
    "    * Question: If you were trying to break DP, where would you start?\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
