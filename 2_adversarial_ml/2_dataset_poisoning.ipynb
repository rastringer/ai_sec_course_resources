{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "957f43d2-187f-4ab6-b7c9-416e3d645548",
   "metadata": {},
   "source": [
    "# Dataset Poisoning \n",
    "\n",
    "Let's examine the effects on classification by poisoning just one image in a dataset of 50,000 (CIFAR10). \n",
    "\n",
    "### CIFAR10\n",
    "\n",
    "The CIFAR10 dataset is another common dataset for computer vision experimentation. It consists of 60,000 color images of 32 x 32 pixels, which fall into 10 classes detailed in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86a9af7-d4e9-48c1-a76b-ba7eeb420078",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import copy\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "# Data loading and preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "print(\"Loading CIFAR-10 dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, \n",
    "                                        download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, \n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "print(f\"Training set size: {len(trainset)} images\")\n",
    "print(f\"Test set size: {len(testset)} images\")\n",
    "\n",
    "# Create data loaders\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, \n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, \n",
    "                                         shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c18f5-e761-4666-831a-76feaa210666",
   "metadata": {},
   "source": [
    "### Convolutions\n",
    "\n",
    "Below, we refer to a 'CNN', a convolutional neural network. CNNs extend the neural networks we have seen already in the previous module by adding a small filter (or 'kernel') to scan across an image to detect specific features, just as humans may do with a magnifying glass.\n",
    "\n",
    "Here are the workings of a convolution:\n",
    "* Filter of 3 x 3 or 5 x 5 pixels (commonly) contains numbers that define the patterns to look for\n",
    "* We place it over a small area of the image and multiply the pixel values with the filter numbers\n",
    "* Add those products to get a single number\n",
    "* Slide the filter to the next position and repeat\n",
    "\n",
    "This creates a 'feature map' that highlights where that pattern appears in the image. The magic of convolutions is that CNNs learn what the filter patterns should be through training. They may start looking for horizontal or vertical edges, curves and textures, and progress to looking for dog ears, or car headlights, depending on the training data. For more on this subject, please have a read of this [paper](https://distill.pub/2017/feature-visualization/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c944ee-168e-44aa-a171-ff4811aa9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple CNN architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # (3, 32, 3) means 3 input channels, 32 output channels.\n",
    "        # (creates 32 feature maps), and kernel size=3 (a 3x3 filter).\n",
    "        # padding adds a 1 pixel border to keep output the same size.\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        # Takes the 32 feature maps from conv1\n",
    "        # Creates 64 new feature maps\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        # Takes 2x2 patches and keeps only the max value\n",
    "        # (reducing image size by half)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # Randomly turns off 50% neurons during training to \n",
    "        # prevent overfitting\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        # 128 * 4 * 4 input size; 512 output neurons\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
    "        # Takes 512 output neurons, multiplies each by learned weight,\n",
    "        # adds them up in different ways (based on each class) \n",
    "        # to produce final 10 output scores\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 4 * 4)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a6476f-ff17-48fc-9f3d-3d1469ab38fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchviz import make_dot\n",
    "from IPython.display import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN()\n",
    "\n",
    "# Dummy input to trace the computation graph\n",
    "x = torch.randn(3, 3, 32, 32).to(device)\n",
    "y = model(x)\n",
    "\n",
    "# Draw graph\n",
    "make_dot(y, params=dict(model.named_parameters())).render(\"model_architecture\", format=\"png\")\n",
    "\n",
    "# Display the saved image\n",
    "Image(filename=\"model_architecture.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c27b15b-7b3b-4897-97c4-b02442216f21",
   "metadata": {},
   "source": [
    "### Benchmark training\n",
    "\n",
    "The various steps in the `train_model` function will hopefully look familiar after the last module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c043b09-e2d4-41bb-892a-8e6393360dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, trainloader, num_epochs=5):\n",
    "    \"\"\"Train the model and return training history\"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(trainloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            if i % 100 == 99:  # Print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}], '\n",
    "                      f'Loss: {running_loss/100:.4f}, '\n",
    "                      f'Accuracy: {100*correct/total:.2f}%')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        epoch_accuracy = 100 * correct / total\n",
    "        train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "    return train_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e49d85f-2601-466c-a971-16da422a56d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, testloader):\n",
    "    \"\"\"Evaluate model and return predictions and true labels\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy, all_predictions, all_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601969d-570f-4f3a-be24-b2c3f8c8564d",
   "metadata": {},
   "source": [
    "### Label flipping\n",
    "\n",
    "The `.targets` in `corrupted_dataset.targets` here is a PyTorch dataset attribute. It is a list of all labels for the dataset.\n",
    "Here all we do is flip the label of one image from source_class 3 (cats) to target_class 5 (dogs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9262b76-6887-452a-b50f-db2ef84088a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_and_corrupt_images(dataset, source_class=3, target_class=5, num_corruptions=1):\n",
    "    \"\"\"Find and corrupt a specified number of images from source_class to target_class\"\"\"\n",
    "    corrupted_dataset = copy.deepcopy(dataset)\n",
    "    \n",
    "    # Find all images of the source class\n",
    "    source_indices = []\n",
    "    for i, label in enumerate(corrupted_dataset.targets):\n",
    "        if label == source_class:\n",
    "            source_indices.append(i)\n",
    "    \n",
    "    if len(source_indices) == 0:\n",
    "        raise ValueError(f\"No images found for source class {source_class}\")\n",
    "    \n",
    "    if num_corruptions > len(source_indices):\n",
    "        raise ValueError(f\"Cannot corrupt {num_corruptions} images - only {len(source_indices)} available for class {source_class}\")\n",
    "    \n",
    "    # Select the first num_corruptions images to corrupt\n",
    "    corrupted_indices = source_indices[:num_corruptions]\n",
    "    \n",
    "    # Corrupt these images\n",
    "    for idx in corrupted_indices:\n",
    "        corrupted_dataset.targets[idx] = target_class\n",
    "    \n",
    "    print(f\"Corrupted {num_corruptions} image(s) from {class_names[source_class]} to {class_names[target_class]}:\")\n",
    "    print(f\"  Indices: {corrupted_indices}\")\n",
    "    print(f\"  Corruption rate: {num_corruptions}/{len(dataset)} = {num_corruptions/len(dataset)*100:.6f}%\")\n",
    "    print(f\"  Percentage of {class_names[source_class]} images affected: {num_corruptions/len(source_indices)*100:.3f}%\")\n",
    "    \n",
    "    return corrupted_dataset, corrupted_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e10613-69ae-4dd9-999a-2bb383baa706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_corruptions(original_dataset, corrupted_dataset, corrupted_indices, max_display=8):\n",
    "    \"\"\"Visualize multiple corrupted images\"\"\"\n",
    "    num_to_show = min(len(corrupted_indices), max_display)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_to_show, figsize=(4*num_to_show, 8))\n",
    "    if num_to_show == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, idx in enumerate(corrupted_indices[:num_to_show]):\n",
    "        # Get images and labels\n",
    "        img, orig_label = original_dataset[idx]\n",
    "        _, corrupt_label = corrupted_dataset[idx]\n",
    "        \n",
    "        # Denormalize image for display\n",
    "        img_display = img.permute(1, 2, 0) * 0.5 + 0.5\n",
    "        \n",
    "        # Show original\n",
    "        axes[0, i].imshow(img_display)\n",
    "        axes[0, i].set_title(f'Original: {class_names[orig_label]}', fontsize=12)\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # Show corrupted (same image, different label)\n",
    "        axes[1, i].imshow(img_display)\n",
    "        axes[1, i].set_title(f'Corrupted: {class_names[corrupt_label]}', \n",
    "                           fontsize=12, color='red')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Corrupted Images: {len(corrupted_indices)} total (showing {num_to_show})', \n",
    "                 fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if len(corrupted_indices) > max_display:\n",
    "        print(f\"Note: Showing first {max_display} corrupted images out of {len(corrupted_indices)} total\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd4bf1-f840-45f9-b8df-4d86c37c156d",
   "metadata": {},
   "source": [
    "### Class distributions\n",
    "\n",
    "Here we compare the counts for each classes in the original and poisoned datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c1af6-4b63-44ca-81b8-9646fdd4f7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_class_distributions(original_dataset, corrupted_dataset):\n",
    "    \"\"\"Compare class distributions between original and corrupted datasets\"\"\"\n",
    "    orig_counts = np.bincount(original_dataset.targets, minlength=10)\n",
    "    corr_counts = np.bincount(corrupted_dataset.targets, minlength=10)\n",
    "    \n",
    "    x = np.arange(len(class_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    bars1 = ax.bar(x - width/2, orig_counts, width, label='Original', alpha=0.7)\n",
    "    bars2 = ax.bar(x + width/2, corr_counts, width, label='Corrupted', alpha=0.7)\n",
    "    \n",
    "    ax.set_ylabel('Number of Images')\n",
    "    ax.set_title('Class Distribution: Original vs Corrupted Dataset')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(class_names, rotation=45)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Highlight the changed classes\n",
    "    for i, (orig, corr) in enumerate(zip(orig_counts, corr_counts)):\n",
    "        if orig != corr:\n",
    "            if orig > corr:  # Source class (lost one image)\n",
    "                ax.annotate(f'-1', xy=(i - width/2, orig), xytext=(0, 5),\n",
    "                           textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                           color='red', fontweight='bold')\n",
    "            else:  # Target class (gained one image)\n",
    "                ax.annotate(f'+1', xy=(i + width/2, corr), xytext=(0, 5),\n",
    "                           textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                           color='green', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae123a-a86c-4f34-9074-bbb84be93a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_comparison(clean_acc, corrupt_acc):\n",
    "    \"\"\"Plot accuracy comparison with emphasis on the small difference\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart comparison\n",
    "    models = ['Clean Model', 'Corrupted Model\\n(1 image changed)']\n",
    "    accuracies = [clean_acc, corrupt_acc]\n",
    "    colors = ['blue', 'red']\n",
    "    \n",
    "    bars = ax1.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "    ax1.set_ylabel('Test Accuracy (%)')\n",
    "    ax1.set_title('Model Performance Comparison')\n",
    "    ax1.set_ylim(0, 100)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, acc in zip(bars, accuracies):\n",
    "        height = bar.get_height()\n",
    "        ax1.annotate(f'{acc:.2f}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                    fontweight='bold')\n",
    "    \n",
    "    # Zoomed view of the difference\n",
    "    ax2.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "    ax2.set_ylabel('Test Accuracy (%)')\n",
    "    ax2.set_title('Zoomed View of Performance Difference')\n",
    "    \n",
    "    # Set y-axis to zoom in on the difference\n",
    "    min_acc = min(accuracies)\n",
    "    max_acc = max(accuracies)\n",
    "    margin = max(0.5, (max_acc - min_acc) * 0.1)\n",
    "    ax2.set_ylim(min_acc - margin, max_acc + margin)\n",
    "    \n",
    "    # Add difference annotation\n",
    "    difference = clean_acc - corrupt_acc\n",
    "    ax2.annotate(f'Difference: {difference:.2f}%', \n",
    "                xy=(0.5, (clean_acc + corrupt_acc) / 2), \n",
    "                xytext=(0.5, (clean_acc + corrupt_acc) / 2 + margin/2),\n",
    "                ha='center', va='center', fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Main experiment\n",
    "# Analyze original dataset composition\n",
    "print(\"\\n1. Analyzing original dataset composition...\")\n",
    "train_class_counts = np.bincount(trainset.targets, minlength=10)\n",
    "test_class_counts = np.bincount(testset.targets, minlength=10)\n",
    "\n",
    "print(\"Training set class distribution:\")\n",
    "for i, count in enumerate(train_class_counts):\n",
    "    print(f\"  {class_names[i]}: {count} images\")\n",
    "\n",
    "print(f\"\\nSpecific focus on cats and dogs in training set:\")\n",
    "print(f\"  Cats (class 3): {train_class_counts[3]} images\")\n",
    "print(f\"  Dogs (class 5): {train_class_counts[5]} images\")\n",
    "print(f\"  Total cat+dog: {train_class_counts[3] + train_class_counts[5]} images\")\n",
    "\n",
    "print(f\"\\nTest set cat and dog counts:\")\n",
    "print(f\"  Cats: {test_class_counts[3]} images\")\n",
    "print(f\"  Dogs: {test_class_counts[5]} images\")\n",
    "\n",
    "# Create corrupted dataset - ADJUST THIS NUMBER TO EXPERIMENT!\n",
    "NUM_CORRUPTIONS = 1  # Change this to try different corruption levels: 1, 5, 10, 50, 100, etc.\n",
    "\n",
    "print(f\"\\n2. Creating dataset with {NUM_CORRUPTIONS} corrupted label(s)...\")\n",
    "corrupted_trainset, corrupted_indices = find_and_corrupt_images(\n",
    "    trainset, source_class=3, target_class=5, num_corruptions=NUM_CORRUPTIONS  # cat -> dog\n",
    ")\n",
    "\n",
    "# Visualize the corruption\n",
    "print(f\"\\n3. Visualizing the {NUM_CORRUPTIONS} corrupted image(s)...\")\n",
    "visualize_corruptions(trainset, corrupted_trainset, corrupted_indices)\n",
    "\n",
    "# Show class distribution changes\n",
    "print(\"\\n4. Showing class distribution changes...\")\n",
    "print(\"After corruption:\")\n",
    "corrupted_class_counts = np.bincount(corrupted_trainset.targets, minlength=10)\n",
    "print(f\"  Cats (class 3): {corrupted_class_counts[3]} images (was {train_class_counts[3]})\")\n",
    "print(f\"  Dogs (class 5): {corrupted_class_counts[5]} images (was {train_class_counts[5]})\")\n",
    "print(f\"  Net change: -{NUM_CORRUPTIONS} cats, +{NUM_CORRUPTIONS} dogs\")\n",
    "\n",
    "compare_class_distributions(trainset, corrupted_trainset)\n",
    "\n",
    "# 5. Create data loaders\n",
    "clean_trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, \n",
    "                                               shuffle=True, num_workers=2)\n",
    "corrupted_trainloader = torch.utils.data.DataLoader(corrupted_trainset, batch_size=128, \n",
    "                                                    shuffle=True, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e31d1a-7a89-43cd-aefa-92a1e13df294",
   "metadata": {},
   "source": [
    "### Running training\n",
    "\n",
    "This is a toy example trained for five epochs so that everyone can run on their machines without needing a GPU. You can of course go further if you have access to accelerators.\n",
    "\n",
    "On CPU, training both models should take less than five minutes. Accuracy is likely to be around 75%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c869fd-d9a3-4cd7-883f-f263f6e75b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on clean data\n",
    "print(\"\\n5. Training model on CLEAN data...\")\n",
    "clean_model = SimpleCNN()\n",
    "clean_train_acc = train_model(clean_model, clean_trainloader, num_epochs=5)\n",
    "clean_test_acc, clean_preds, clean_labels = evaluate_model(clean_model, testloader)\n",
    "print(f\"Clean model test accuracy: {clean_test_acc:.2f}%\")\n",
    "\n",
    "# Train model on corrupted data\n",
    "print(f\"\\n6. Training model on data with {NUM_CORRUPTIONS} corrupted label(s)...\")\n",
    "corrupt_model = SimpleCNN()\n",
    "corrupt_train_acc = train_model(corrupt_model, corrupted_trainloader, num_epochs=5)\n",
    "corrupt_test_acc, corrupt_preds, corrupt_labels = evaluate_model(corrupt_model, testloader)\n",
    "print(f\"Corrupted model test accuracy: {corrupt_test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58221f-3b60-476d-9db4-8fcb8e7c3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size: {len(trainset)} images\")\n",
    "print(f\"Original cats: {train_class_counts[3]} images\")\n",
    "print(f\"Original dogs: {train_class_counts[5]} images\")\n",
    "print(f\"After corruption: {corrupted_class_counts[3]} cats, {corrupted_class_counts[5]} dogs\")\n",
    "print(f\"Corrupted images: {NUM_CORRUPTIONS}\")\n",
    "print(f\"Clean Model Test Accuracy:     {clean_test_acc:.3f}%\")\n",
    "print(f\"Corrupted Model Test Accuracy: {corrupt_test_acc:.3f}%\")\n",
    "print(f\"Performance Change:            {corrupt_test_acc - clean_test_acc:.3f}%\")\n",
    "print(f\"Corruption Rate:               {NUM_CORRUPTIONS}/{len(trainset)} = {NUM_CORRUPTIONS/len(trainset)*100:.6f}%\")\n",
    "\n",
    "# Visualize the comparison\n",
    "print(\"\\nVisualizing performance comparison...\")\n",
    "plot_accuracy_comparison(clean_test_acc, corrupt_test_acc)\n",
    "\n",
    "# Calculate Cat vs Dog specific accuracy\n",
    "print(\"\\nAnalyzing Cat vs Dog classification specifically...\")\n",
    "print(f\"Reminder - Training set had:\")\n",
    "print(f\"  Original: {train_class_counts[3]} cats, {train_class_counts[5]} dogs\")\n",
    "print(f\"  Corrupted: {corrupted_class_counts[3]} cats, {corrupted_class_counts[5]} dogs\")\n",
    "print(f\"  Change: {NUM_CORRUPTIONS} cats became {NUM_CORRUPTIONS} dogs (out of {train_class_counts[3]} cats)\")\n",
    "print(f\"  Percentage of cats affected: {NUM_CORRUPTIONS/train_class_counts[3]*100:.3f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07425f6-3996-4587-8c0b-82bd2d5c3293",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "There isn't much difference in overall accuracy. Looking specifically at the two classes affected by the label flip (where we changed a cat to a dog) tells a different story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4563ece2-f953-453e-a6cc-f5b02480c64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cat_dog_accuracy(predictions, labels):\n",
    "    \"\"\"Calculate accuracy for cats and dogs separately\"\"\"\n",
    "    cat_indices = [i for i, label in enumerate(labels) if label == 3]  # cats\n",
    "    dog_indices = [i for i, label in enumerate(labels) if label == 5]  # dogs\n",
    "    \n",
    "    # Cat accuracy\n",
    "    cat_correct = sum(1 for i in cat_indices if predictions[i] == 3)\n",
    "    cat_accuracy = cat_correct / len(cat_indices) if cat_indices else 0\n",
    "    \n",
    "    # Dog accuracy\n",
    "    dog_correct = sum(1 for i in dog_indices if predictions[i] == 5)\n",
    "    dog_accuracy = dog_correct / len(dog_indices) if dog_indices else 0\n",
    "    \n",
    "    # Combined cat+dog accuracy\n",
    "    cat_dog_indices = cat_indices + dog_indices\n",
    "    cat_dog_correct = sum(1 for i in cat_dog_indices if predictions[i] == labels[i])\n",
    "    cat_dog_accuracy = cat_dog_correct / len(cat_dog_indices) if cat_dog_indices else 0\n",
    "    \n",
    "    return cat_accuracy, dog_accuracy, cat_dog_accuracy, len(cat_indices), len(dog_indices)\n",
    "\n",
    "# Calculate accuracies for both models\n",
    "clean_cat_acc, clean_dog_acc, clean_cat_dog_acc, num_cats, num_dogs = calculate_cat_dog_accuracy(clean_preds, clean_labels)\n",
    "corrupt_cat_acc, corrupt_dog_acc, corrupt_cat_dog_acc, _, _ = calculate_cat_dog_accuracy(corrupt_preds, corrupt_labels)\n",
    "\n",
    "print(f\"Test set contains {num_cats} cats and {num_dogs} dogs\")\n",
    "print(\"\\nCat Classification Accuracy:\")\n",
    "print(f\"  Clean Model:     {clean_cat_acc:.3f}% ({clean_cat_acc*100:.1f}%)\")\n",
    "print(f\"  Corrupted Model: {corrupt_cat_acc:.3f}% ({corrupt_cat_acc*100:.1f}%)\")\n",
    "print(f\"  Difference:      {corrupt_cat_acc - clean_cat_acc:.3f}% ({(corrupt_cat_acc - clean_cat_acc)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nDog Classification Accuracy:\")\n",
    "print(f\"  Clean Model:     {clean_dog_acc:.3f}% ({clean_dog_acc*100:.1f}%)\")\n",
    "print(f\"  Corrupted Model: {corrupt_dog_acc:.3f}% ({corrupt_dog_acc*100:.1f}%)\")\n",
    "print(f\"  Difference:      {corrupt_dog_acc - clean_dog_acc:.3f}% ({(corrupt_dog_acc - clean_dog_acc)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c15b70-2b49-48c9-a251-6f2d2d742754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cat vs dog accuracy comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Cat accuracy comparison\n",
    "categories = ['Clean Model', 'Corrupted Model']\n",
    "cat_accuracies = [clean_cat_acc * 100, corrupt_cat_acc * 100]\n",
    "bars1 = axes[0].bar(categories, cat_accuracies, color=['blue', 'red'], alpha=0.7)\n",
    "axes[0].set_ylabel('Accuracy (%)')\n",
    "axes[0].set_title('Cat Classification Accuracy')\n",
    "axes[0].set_ylim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars1, cat_accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[0].annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                    fontweight='bold')\n",
    "\n",
    "# Dog accuracy comparison\n",
    "dog_accuracies = [clean_dog_acc * 100, corrupt_dog_acc * 100]\n",
    "bars2 = axes[1].bar(categories, dog_accuracies, color=['blue', 'red'], alpha=0.7)\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Dog Classification Accuracy')\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars2, dog_accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[1].annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                    fontweight='bold')\n",
    "\n",
    "# Combined cat+dog accuracy comparison\n",
    "cat_dog_accuracies = [clean_cat_dog_acc * 100, corrupt_cat_dog_acc * 100]\n",
    "bars3 = axes[2].bar(categories, cat_dog_accuracies, color=['blue', 'red'], alpha=0.7)\n",
    "axes[2].set_ylabel('Accuracy (%)')\n",
    "axes[2].set_title('Combined Cat+Dog Accuracy')\n",
    "axes[2].set_ylim(0, 100)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars3, cat_dog_accuracies):\n",
    "    height = bar.get_height()\n",
    "    axes[2].annotate(f'{acc:.1f}%', xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3), textcoords=\"offset points\", ha='center', va='bottom',\n",
    "                    fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create confusion matrix comparison for affected classes\n",
    "print(\"\\n10. Confusion matrix comparison for Cat vs Dog classification...\")\n",
    "cat_dog_indices = [i for i, label in enumerate(clean_labels) if label in [3, 5]]\n",
    "cat_dog_true = [clean_labels[i] for i in cat_dog_indices]\n",
    "cat_dog_clean_pred = [clean_preds[i] for i in cat_dog_indices]\n",
    "cat_dog_corrupt_pred = [corrupt_preds[i] for i in cat_dog_indices]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Clean model - cats vs dogs only\n",
    "cm_clean = confusion_matrix(cat_dog_true, cat_dog_clean_pred, labels=[3, 5])\n",
    "sns.heatmap(cm_clean, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=ax1)\n",
    "ax1.set_title('Clean Model: Cat vs Dog')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# Corrupted model - cats vs dogs only\n",
    "cm_corrupt = confusion_matrix(cat_dog_true, cat_dog_corrupt_pred, labels=[3, 5])\n",
    "sns.heatmap(cm_corrupt, annot=True, fmt='d', cmap='Reds', \n",
    "            xticklabels=['Cat', 'Dog'], yticklabels=['Cat', 'Dog'], ax=ax2)\n",
    "ax2.set_title('Corrupted Model: Cat vs Dog')\n",
    "ax2.set_ylabel('True Label')\n",
    "ax2.set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"1. Training set: {len(trainset)} images total\")\n",
    "print(f\"   - Cats: {train_class_counts[3]} images\")\n",
    "print(f\"   - Dogs: {train_class_counts[5]} images\")\n",
    "print(f\"2. Changed {NUM_CORRUPTIONS} cat(s) → dog(s) (affected {NUM_CORRUPTIONS/train_class_counts[3]*100:.3f}% of cat training data)\")\n",
    "print(f\"3. This small change ({NUM_CORRUPTIONS/len(trainset)*100:.6f}% of total data) affects performance.\")\n",
    "print(f\"4. Cat classification accuracy was reduced by {round(corrupt_cat_acc - clean_cat_acc, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b133122-c3dc-4da0-bd5f-294d06d9b0f6",
   "metadata": {},
   "source": [
    "In this notebook, we showed that changing just one label in a dataset of 60,000 images can have a significant impact on related classes. It is worth bearing in mind of course that this is a small model with minimal training intended to highlight the various processes and attacks we will cover in this course. More robust models will be less suceptible to such attacks, however the outsized complications that a small dataset poisoning can have through the network is worthy of considerations. \n",
    "\n",
    "# Dataset Defences\n",
    "\n",
    "<img src=\"images/defence.png\" align=right width=350>\n",
    "\n",
    "Now we have seen the outsized affect one flipped label in a training dataset\n",
    "can have on a model, let's consider some defences against dataset poisoning. \n",
    "\n",
    "## Data Pipeline \n",
    "\n",
    "#### Input Validation and Sanitization\n",
    "\n",
    "Many organizations will continually update their training data, especially when their tasks are dynamic (predictions in ever-evolving fields with constantly evolving data). Some defences may include:\n",
    "* schema validation for incoming data\n",
    "* bounds checking for features / length limits for text / image sizes, standards and content\n",
    "* statistical outlier detection\n",
    "\n",
    "#### Data provenence tracking\n",
    "\n",
    "We need careful oversight of where data is actually coming from. Some best practices include:\n",
    "* logging systems to record data sources, collection and labelling methods\n",
    "* cryptographic signatures or hashes to verify data integrity\n",
    "* clear access log trail showing who accessed or modified data\n",
    "\n",
    "#### Monitoring\n",
    "\n",
    "Monitoring is a key defence for the majority of ML-centric and other attacks.\n",
    "* Detect shifts in data distribution\n",
    "* Monitor data quality metrics\n",
    "* Alerts for changes in data patterns\n",
    "* Track model accuracy and alert on changes possibly caused by data poisoning\n",
    "\n",
    "## Access control\n",
    "\n",
    "Organizations can require strong authentication and access level controls (ACLs) for teams working with data. These include:\n",
    "* authentication, especially for data write access\n",
    "* data segregation - separate training, validation and test data with different access levels\n",
    "* air-gapped environments for critical model training\n",
    "* approvals for data additions or modifications\n",
    "\n",
    "## Screening\n",
    "\n",
    "We an also use statistical and other methods to check for potentially compromised datasets. This is especially useful since many organizations will use open source or purchased datasets created elsewhere.\n",
    "\n",
    "#### Statistical analysis \n",
    "* compare data distributions against baselines\n",
    "* use clustering analysis to identify unusual groupings\n",
    "* correlation analysis to detect unexpected feature relationships\n",
    "\n",
    "#### Use ML!\n",
    "* Model based detection - train separate models on subsets of data and compare performance\n",
    "* Use feature importance analysis to identify high-impact training examples\n",
    "* Try gradient-based methods to detect adversarial examples.\n",
    "    * 'gradient magnitude' can show the model may be making decisions on\n",
    "       fragile features that may be adversarially crafted\n",
    "    * Gradient-based clustering can show poisoned examples forming distinct clusters or as outliers\n",
    "    * These can be expensive and add cost and time to training preparation\n",
    "* LLMs to detect unusual language content\n",
    "  \n",
    "\n",
    "\n",
    "For futher experimentation, try this approach with different datasets and perhaps more sophisticated models. Or simply try increasing the number of flipped labels in this example - how many labels of cats do you have to change to 'dog' to make accuracy drop below 30% on cat classification?\n",
    "\n",
    "### Discussion\n",
    "\n",
    "What data pipelines have you worked with and how could you help to secure them? \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
