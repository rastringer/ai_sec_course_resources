Explore one of these research directions for 1-2 hours:

<img src="https://github.com/rastringer/ai_sec_course_resources/blob/main/2_adversarial_ml/images/adversarial_ml.png?raw=true" width="250" align="right" alt="Adversarial ML Image">

* Try stronger attacks, such as DeepFool, AutoAttack or C&W.
* Try other defences, such as randomized smoothing or defensive distillation. 
* Looking at transferability across models can be very interesting, do the adversarial examples prove similarly effective?
* Experiment with pretrained (and more robust) models such as ResNet18 or MobileNet.
* Look for examples of creating adversarial audio or text examples and try to implement a demo.